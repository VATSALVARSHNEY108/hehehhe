import streamlit as st
import zipfile
import tarfile
import json
import csv
import xml.etree.ElementTree as ET
import io
import os
import hashlib
import shutil
from datetime import datetime
import mimetypes
import base64
from pathlib import Path
import pandas as pd
from utils.common import create_tool_header, show_progress_bar, add_to_recent
from utils.file_handler import FileHandler


def display_tools():
    """Display all file management tools"""

    tool_categories = {
        "File Converters": [
            "Document Converter", "Image Format Converter", "Audio Converter", "Video Converter", "Archive Converter"
        ],
        "File Compression": [
            "ZIP Creator", "Archive Manager", "Compression Optimizer", "Batch Compressor", "Archive Extractor"
        ],
        "File Metadata Editors": [
            "EXIF Editor", "Property Editor", "Tag Manager", "Information Extractor", "Metadata Cleaner"
        ],
        "Batch File Processors": [
            "Bulk Renamer", "Mass Converter", "Batch Processor", "File Organizer", "Bulk Operations"
        ],
        "File Organizers": [
            "Directory Manager", "File Sorter", "Duplicate Finder", "Folder Organizer", "Smart Organizer"
        ],
        "File Backup Utilities": [
            "Backup Creator", "Sync Manager", "Version Control", "Backup Scheduler", "Recovery Tools"
        ],
        "File Sync Tools": [
            "Directory Sync", "Cloud Sync", "File Mirror", "Sync Scheduler", "Conflict Resolver"
        ],
        "File Analysis Tools": [
            "Size Analyzer", "Type Detector", "Content Scanner", "Duplicate Detector", "File Statistics"
        ],
        "File Security": [
            "File Encryption", "Password Protection", "Secure Delete", "Integrity Checker", "Access Control"
        ],
        "File Utilities": [
            "File Splitter", "File Merger", "Checksum Generator", "File Monitor", "Path Manager"
        ]
    }

    selected_category = st.selectbox("Select File Tool Category", list(tool_categories.keys()))
    selected_tool = st.selectbox("Select Tool", tool_categories[selected_category])

    st.markdown("---")

    add_to_recent(f"File Tools - {selected_tool}")

    # Display selected tool
    if selected_tool == "Document Converter":
        document_converter()
    elif selected_tool == "ZIP Creator":
        zip_creator()
    elif selected_tool == "Bulk Renamer":
        bulk_renamer()
    elif selected_tool == "Duplicate Finder":
        duplicate_finder()
    elif selected_tool == "File Encryption":
        file_encryption()
    elif selected_tool == "Size Analyzer":
        size_analyzer()
    elif selected_tool == "Archive Manager":
        archive_manager()
    elif selected_tool == "Property Editor":
        property_editor()
    elif selected_tool == "File Splitter":
        file_splitter()
    elif selected_tool == "Checksum Generator":
        checksum_generator()
    elif selected_tool == "Directory Sync":
        directory_sync()
    elif selected_tool == "Content Scanner":
        content_scanner()
    elif selected_tool == "Backup Creator":
        backup_creator()
    elif selected_tool == "File Monitor":
        file_monitor()
    elif selected_tool == "Smart Organizer":
        smart_organizer()
    else:
        st.info(f"{selected_tool} tool is being implemented. Please check back soon!")


def document_converter():
    """Convert documents between formats"""
    create_tool_header("Document Converter", "Convert documents between various formats", "üìÑ")

    uploaded_files = FileHandler.upload_files(['pdf', 'docx', 'txt', 'rtf', 'odt', 'html'], accept_multiple=True)

    if uploaded_files:
        target_format = st.selectbox("Target Format", ["PDF", "DOCX", "TXT", "HTML", "RTF", "JSON"])

        conversion_options = {}

        if target_format == "PDF":
            conversion_options['page_size'] = st.selectbox("Page Size", ["A4", "Letter", "Legal", "A3"])
            conversion_options['orientation'] = st.selectbox("Orientation", ["Portrait", "Landscape"])

        elif target_format == "HTML":
            conversion_options['include_css'] = st.checkbox("Include CSS Styling", True)
            conversion_options['responsive'] = st.checkbox("Make Responsive", True)

        elif target_format == "TXT":
            conversion_options['encoding'] = st.selectbox("Text Encoding", ["UTF-8", "ASCII", "Latin-1"])
            conversion_options['line_ending'] = st.selectbox("Line Endings",
                                                             ["LF (Unix)", "CRLF (Windows)", "CR (Mac)"])

        if st.button("Convert Documents"):
            converted_files = {}
            progress_bar = st.progress(0)

            for i, uploaded_file in enumerate(uploaded_files):
                try:
                    # Extract content based on file type
                    content = extract_document_content(uploaded_file)

                    if content:
                        # Convert to target format
                        converted_content = convert_document_content(content, target_format, conversion_options)

                        # Generate filename
                        base_name = uploaded_file.name.rsplit('.', 1)[0]
                        new_filename = f"{base_name}_converted.{target_format.lower()}"

                        converted_files[new_filename] = converted_content

                    progress_bar.progress((i + 1) / len(uploaded_files))

                except Exception as e:
                    st.error(f"Error converting {uploaded_file.name}: {str(e)}")

            if converted_files:
                st.success(f"Converted {len(converted_files)} document(s) to {target_format}")

                if len(converted_files) == 1:
                    filename, content = next(iter(converted_files.items()))
                    mime_type = get_mime_type(target_format)
                    FileHandler.create_download_link(content, filename, mime_type)
                else:
                    zip_data = FileHandler.create_zip_archive(converted_files)
                    FileHandler.create_download_link(zip_data, f"converted_documents.zip", "application/zip")


def zip_creator():
    """Create ZIP archives from multiple files"""
    create_tool_header("ZIP Creator", "Create compressed ZIP archives", "üì¶")

    uploaded_files = FileHandler.upload_files(['*'], accept_multiple=True)

    if uploaded_files:
        st.subheader("Archive Settings")

        col1, col2 = st.columns(2)
        with col1:
            archive_name = st.text_input("Archive Name", "my_archive")
            compression_level = st.slider("Compression Level", 0, 9, 6)

        with col2:
            password_protect = st.checkbox("Password Protection")
            if password_protect:
                password = st.text_input("Archive Password", type="password")

        # File organization
        st.subheader("File Organization")
        organize_by = st.selectbox("Organize Files By", ["None", "File Type", "Date", "Size", "Custom Folders"])

        if organize_by == "Custom Folders":
            folder_structure = st.text_area("Folder Structure (one per line)",
                                            "documents/\nimages/\narchives/")

        if st.button("Create ZIP Archive"):
            try:
                # Create ZIP archive
                zip_buffer = io.BytesIO()

                with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED,
                                     compresslevel=compression_level) as zip_file:
                    progress_bar = st.progress(0)

                    for i, uploaded_file in enumerate(uploaded_files):
                        # Determine file path in archive
                        if organize_by == "File Type":
                            file_ext = uploaded_file.name.split('.')[-1].lower()
                            archive_path = f"{file_ext}_files/{uploaded_file.name}"
                        elif organize_by == "Date":
                            archive_path = f"{datetime.now().strftime('%Y-%m-%d')}/{uploaded_file.name}"
                        elif organize_by == "Size":
                            size_category = get_size_category(uploaded_file.size)
                            archive_path = f"{size_category}/{uploaded_file.name}"
                        else:
                            archive_path = uploaded_file.name

                        # Add file to archive
                        file_data = uploaded_file.read()
                        zip_file.writestr(archive_path, file_data)

                        progress_bar.progress((i + 1) / len(uploaded_files))

                zip_data = zip_buffer.getvalue()

                # Archive statistics
                st.subheader("Archive Statistics")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Files Added", len(uploaded_files))
                with col2:
                    original_size = sum(f.size for f in uploaded_files)
                    st.metric("Original Size", f"{original_size:,} bytes")
                with col3:
                    compression_ratio = (1 - len(zip_data) / original_size) * 100 if original_size > 0 else 0
                    st.metric("Compression", f"{compression_ratio:.1f}%")

                # Download archive
                FileHandler.create_download_link(
                    zip_data,
                    f"{archive_name}.zip",
                    "application/zip"
                )

                st.success("ZIP archive created successfully!")

            except Exception as e:
                st.error(f"Error creating ZIP archive: {str(e)}")


def bulk_renamer():
    """Bulk rename multiple files"""
    create_tool_header("Bulk Renamer", "Rename multiple files with patterns", "üìù")

    uploaded_files = FileHandler.upload_files(['*'], accept_multiple=True)

    if uploaded_files:
        st.subheader("Renaming Options")

        rename_method = st.selectbox("Renaming Method", [
            "Add Prefix/Suffix", "Replace Text", "Sequential Numbering", "Date/Time Stamp", "Pattern Replacement"
        ])

        if rename_method == "Add Prefix/Suffix":
            prefix = st.text_input("Prefix", "")
            suffix = st.text_input("Suffix", "")

        elif rename_method == "Replace Text":
            find_text = st.text_input("Find Text", "")
            replace_text = st.text_input("Replace With", "")
            case_sensitive = st.checkbox("Case Sensitive", True)

        elif rename_method == "Sequential Numbering":
            base_name = st.text_input("Base Name", "file")
            start_number = st.number_input("Start Number", min_value=1, value=1)
            number_format = st.selectbox("Number Format", ["001", "01", "1", "(1)", "[1]"])

        elif rename_method == "Date/Time Stamp":
            date_format = st.selectbox("Date Format", [
                "%Y-%m-%d", "%Y%m%d", "%d-%m-%Y", "%m-%d-%Y"
            ])
            time_format = st.selectbox("Time Format", [
                "None", "%H%M%S", "%H-%M-%S", "%I%M%p"
            ])
            position = st.selectbox("Position", ["Prefix", "Suffix"])

        elif rename_method == "Pattern Replacement":
            pattern = st.text_input("Pattern (use {n} for number, {name} for original name)", "{name}_{n}")

        # Preview changes
        if st.button("Preview Changes"):
            preview_names = []

            for i, uploaded_file in enumerate(uploaded_files):
                original_name = uploaded_file.name
                name_without_ext = original_name.rsplit('.', 1)[0]
                extension = original_name.rsplit('.', 1)[1] if '.' in original_name else ''

                if rename_method == "Add Prefix/Suffix":
                    new_name = f"{prefix}{name_without_ext}{suffix}"

                elif rename_method == "Replace Text":
                    if case_sensitive:
                        new_name = name_without_ext.replace(find_text, replace_text)
                    else:
                        new_name = name_without_ext.lower().replace(find_text.lower(), replace_text)

                elif rename_method == "Sequential Numbering":
                    number = start_number + i
                    if number_format == "001":
                        number_str = f"{number:03d}"
                    elif number_format == "01":
                        number_str = f"{number:02d}"
                    elif number_format == "(1)":
                        number_str = f"({number})"
                    elif number_format == "[1]":
                        number_str = f"[{number}]"
                    else:
                        number_str = str(number)
                    new_name = f"{base_name}_{number_str}"

                elif rename_method == "Date/Time Stamp":
                    timestamp = datetime.now().strftime(date_format)
                    if time_format != "None":
                        timestamp += "_" + datetime.now().strftime(time_format)

                    if position == "Prefix":
                        new_name = f"{timestamp}_{name_without_ext}"
                    else:
                        new_name = f"{name_without_ext}_{timestamp}"

                elif rename_method == "Pattern Replacement":
                    new_name = pattern.replace("{n}", str(i + 1)).replace("{name}", name_without_ext)

                if extension:
                    new_name += f".{extension}"

                preview_names.append((original_name, new_name))

            # Display preview
            st.subheader("Rename Preview")
            for original, new in preview_names:
                col1, col2, col3 = st.columns([2, 1, 2])
                with col1:
                    st.write(original)
                with col2:
                    st.write("‚Üí")
                with col3:
                    st.write(new)

        # Generate rename script
        if st.button("Generate Rename Script"):
            script_content = generate_rename_script(uploaded_files, rename_method, locals())

            st.subheader("Rename Script")
            st.code(script_content, language="bash")

            FileHandler.create_download_link(
                script_content.encode(),
                "rename_script.sh",
                "text/plain"
            )


def duplicate_finder():
    """Find duplicate files"""
    create_tool_header("Duplicate Finder", "Find and manage duplicate files", "üîç")

    uploaded_files = FileHandler.upload_files(['*'], accept_multiple=True)

    if uploaded_files:
        st.subheader("Duplicate Detection Settings")

        comparison_method = st.selectbox("Comparison Method", [
            "File Content (MD5)", "File Size", "File Name", "Content + Size"
        ])

        ignore_extensions = st.checkbox("Ignore File Extensions")
        case_sensitive = st.checkbox("Case Sensitive Names", True)

        if st.button("Find Duplicates"):
            with st.spinner("Analyzing files for duplicates..."):
                duplicates = find_duplicates(uploaded_files, comparison_method, ignore_extensions, case_sensitive)

                if duplicates:
                    st.subheader("Duplicate Files Found")

                    total_duplicates = sum(len(group) - 1 for group in duplicates.values())
                    st.warning(f"Found {total_duplicates} duplicate files in {len(duplicates)} groups")

                    for i, (key, files) in enumerate(duplicates.items(), 1):
                        with st.expander(f"Duplicate Group {i} ({len(files)} files)"):
                            for j, file_info in enumerate(files):
                                col1, col2, col3 = st.columns([3, 1, 1])
                                with col1:
                                    st.write(f"üìÑ {file_info['name']}")
                                with col2:
                                    st.write(f"{file_info['size']:,} bytes")
                                with col3:
                                    if j > 0:  # Mark as duplicate (keep first as original)
                                        st.write("üîÑ Duplicate")
                                    else:
                                        st.write("üìå Original")

                            # Show duplicate info
                            if comparison_method == "File Content (MD5)":
                                st.code(f"MD5: {key}")

                    # Generate duplicate report
                    if st.button("Generate Duplicate Report"):
                        report = generate_duplicate_report(duplicates, comparison_method)
                        FileHandler.create_download_link(
                            report.encode(),
                            "duplicate_files_report.txt",
                            "text/plain"
                        )
                else:
                    st.success("üéâ No duplicate files found!")


def file_encryption():
    """Encrypt and decrypt files"""
    create_tool_header("File Encryption", "Secure file encryption and decryption", "üîê")

    operation = st.radio("Operation", ["Encrypt Files", "Decrypt Files"])

    if operation == "Encrypt Files":
        uploaded_files = FileHandler.upload_files(['*'], accept_multiple=True)

        if uploaded_files:
            st.subheader("Encryption Settings")

            col1, col2 = st.columns(2)
            with col1:
                encryption_method = st.selectbox("Encryption Method", ["AES-256", "AES-128", "ChaCha20"])
                password = st.text_input("Encryption Password", type="password")

            with col2:
                key_derivation = st.selectbox("Key Derivation", ["PBKDF2", "Scrypt", "Argon2"])
                confirm_password = st.text_input("Confirm Password", type="password")

            if password and confirm_password:
                if password != confirm_password:
                    st.error("Passwords do not match!")
                else:
                    if st.button("Encrypt Files"):
                        encrypted_files = encrypt_files(uploaded_files, password, encryption_method, key_derivation)

                        if encrypted_files:
                            st.success(f"Encrypted {len(encrypted_files)} file(s)")

                            if len(encrypted_files) == 1:
                                filename, data = next(iter(encrypted_files.items()))
                                FileHandler.create_download_link(data, filename, "application/octet-stream")
                            else:
                                zip_data = FileHandler.create_zip_archive(encrypted_files)
                                FileHandler.create_download_link(zip_data, "encrypted_files.zip", "application/zip")

    else:  # Decrypt Files
        uploaded_files = FileHandler.upload_files(['enc', 'encrypted'], accept_multiple=True)

        if uploaded_files:
            password = st.text_input("Decryption Password", type="password")

            if password and st.button("Decrypt Files"):
                decrypted_files = decrypt_files(uploaded_files, password)

                if decrypted_files:
                    st.success(f"Decrypted {len(decrypted_files)} file(s)")

                    if len(decrypted_files) == 1:
                        filename, data = next(iter(decrypted_files.items()))
                        FileHandler.create_download_link(data, filename, "application/octet-stream")
                    else:
                        zip_data = FileHandler.create_zip_archive(decrypted_files)
                        FileHandler.create_download_link(zip_data, "decrypted_files.zip", "application/zip")


def size_analyzer():
    """Analyze file and folder sizes"""
    create_tool_header("Size Analyzer", "Analyze file sizes and storage usage", "üìä")

    uploaded_files = FileHandler.upload_files(['*'], accept_multiple=True)

    if uploaded_files:
        if st.button("Analyze File Sizes"):
            # Calculate total size and statistics
            total_size = sum(f.size for f in uploaded_files)
            avg_size = total_size / len(uploaded_files)
            largest_file = max(uploaded_files, key=lambda f: f.size)
            smallest_file = min(uploaded_files, key=lambda f: f.size)

            # Display summary statistics
            st.subheader("Size Analysis Summary")

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total Files", len(uploaded_files))
            with col2:
                st.metric("Total Size", format_bytes(total_size))
            with col3:
                st.metric("Average Size", format_bytes(avg_size))
            with col4:
                st.metric("Size Range", f"{format_bytes(smallest_file.size)} - {format_bytes(largest_file.size)}")

            # File type breakdown
            st.subheader("File Type Breakdown")
            file_types = {}
            for file in uploaded_files:
                ext = file.name.split('.')[-1].lower() if '.' in file.name else 'no extension'
                if ext not in file_types:
                    file_types[ext] = {'count': 0, 'size': 0}
                file_types[ext]['count'] += 1
                file_types[ext]['size'] += file.size

            # Display file type statistics
            for ext, stats in sorted(file_types.items(), key=lambda x: x[1]['size'], reverse=True):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.write(f"**.{ext}**")
                with col2:
                    st.write(f"{stats['count']} files")
                with col3:
                    st.write(f"{format_bytes(stats['size'])}")

            # Size distribution
            st.subheader("Size Distribution")
            size_ranges = {
                "< 1 KB": 0, "1-10 KB": 0, "10-100 KB": 0, "100 KB - 1 MB": 0,
                "1-10 MB": 0, "10-100 MB": 0, "> 100 MB": 0
            }

            for file in uploaded_files:
                size = file.size
                if size < 1024:
                    size_ranges["< 1 KB"] += 1
                elif size < 10 * 1024:
                    size_ranges["1-10 KB"] += 1
                elif size < 100 * 1024:
                    size_ranges["10-100 KB"] += 1
                elif size < 1024 * 1024:
                    size_ranges["100 KB - 1 MB"] += 1
                elif size < 10 * 1024 * 1024:
                    size_ranges["1-10 MB"] += 1
                elif size < 100 * 1024 * 1024:
                    size_ranges["10-100 MB"] += 1
                else:
                    size_ranges["> 100 MB"] += 1

            for range_name, count in size_ranges.items():
                if count > 0:
                    st.write(f"**{range_name}**: {count} files")

            # Detailed file list
            st.subheader("Detailed File List")
            file_data = []
            for file in sorted(uploaded_files, key=lambda f: f.size, reverse=True):
                file_data.append({
                    "Name": file.name,
                    "Size": format_bytes(file.size),
                    "Type": file.name.split('.')[-1].upper() if '.' in file.name else 'Unknown'
                })

            df = pd.DataFrame(file_data)
            st.dataframe(df, use_container_width=True)

            # Generate analysis report
            if st.button("Generate Analysis Report"):
                report = generate_size_analysis_report(uploaded_files, file_types, size_ranges)
                FileHandler.create_download_link(
                    report.encode(),
                    "size_analysis_report.txt",
                    "text/plain"
                )


# Helper Functions

def extract_document_content(uploaded_file):
    """Extract content from various document formats"""
    try:
        if uploaded_file.name.endswith('.txt'):
            return FileHandler.process_text_file(uploaded_file)
        elif uploaded_file.name.endswith('.json'):
            return FileHandler.process_json_file(uploaded_file)
        elif uploaded_file.name.endswith('.csv'):
            df = FileHandler.process_csv_file(uploaded_file)
            return df.to_string() if df is not None else None
        else:
            # For other formats, return as text or binary
            content = uploaded_file.read()
            try:
                return content.decode('utf-8')
            except:
                return content
    except Exception as e:
        st.error(f"Error extracting content: {str(e)}")
        return None


def convert_document_content(content, target_format, options):
    """Convert document content to target format"""
    if target_format == "TXT":
        if isinstance(content, bytes):
            return content
        encoding = options.get('encoding', 'UTF-8')
        return content.encode(encoding)

    elif target_format == "HTML":
        html_content = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Converted Document</title>
    {'<meta name="viewport" content="width=device-width, initial-scale=1.0">' if options.get('responsive') else ''}
    {'<style>body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }</style>' if options.get('include_css') else ''}
</head>
<body>
    <pre>{content}</pre>
</body>
</html>"""
        return html_content.encode('utf-8')

    elif target_format == "JSON":
        json_content = {
            "content": content if isinstance(content, str) else content.decode('utf-8', errors='ignore'),
            "converted_at": datetime.now().isoformat(),
            "format": target_format
        }
        return json.dumps(json_content, indent=2).encode('utf-8')

    else:
        # Default: return as-is
        return content if isinstance(content, bytes) else content.encode('utf-8')


def get_mime_type(file_format):
    """Get MIME type for file format"""
    mime_types = {
        'PDF': 'application/pdf',
        'DOCX': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
        'TXT': 'text/plain',
        'HTML': 'text/html',
        'JSON': 'application/json',
        'RTF': 'application/rtf'
    }
    return mime_types.get(file_format, 'application/octet-stream')


def get_size_category(size):
    """Categorize file by size"""
    if size < 1024 * 1024:  # < 1MB
        return "small_files"
    elif size < 10 * 1024 * 1024:  # < 10MB
        return "medium_files"
    else:
        return "large_files"


def generate_rename_script(files, method, variables):
    """Generate bash script for renaming files"""
    script = "#!/bin/bash\n\n"
    script += "# Bulk rename script generated by File Tools\n"
    script += f"# Method: {method}\n"
    script += f"# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"

    for i, file in enumerate(files):
        original_name = file.name
        # Generate new name based on method
        new_name = f"renamed_file_{i + 1}.{original_name.split('.')[-1]}"
        script += f'mv "{original_name}" "{new_name}"\n'

    return script


def find_duplicates(files, method, ignore_ext, case_sensitive):
    """Find duplicate files based on specified method"""
    file_groups = {}

    for file in files:
        if method == "File Content (MD5)":
            key = hashlib.md5(file.read()).hexdigest()
            file.seek(0)  # Reset file pointer
        elif method == "File Size":
            key = file.size
        elif method == "File Name":
            name = file.name
            if ignore_ext and '.' in name:
                name = name.rsplit('.', 1)[0]
            if not case_sensitive:
                name = name.lower()
            key = name
        elif method == "Content + Size":
            content_hash = hashlib.md5(file.read()).hexdigest()
            file.seek(0)
            key = f"{content_hash}_{file.size}"

        if key not in file_groups:
            file_groups[key] = []

        file_groups[key].append({
            'name': file.name,
            'size': file.size,
            'file_obj': file
        })

    # Return only groups with duplicates
    return {k: v for k, v in file_groups.items() if len(v) > 1}


def generate_duplicate_report(duplicates, method):
    """Generate duplicate files report"""
    report = "DUPLICATE FILES REPORT\n"
    report += "=" * 50 + "\n\n"
    report += f"Detection Method: {method}\n"
    report += f"Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"

    total_duplicates = sum(len(group) - 1 for group in duplicates.values())
    report += f"Total Duplicate Files: {total_duplicates}\n"
    report += f"Duplicate Groups: {len(duplicates)}\n\n"

    for i, (key, files) in enumerate(duplicates.items(), 1):
        report += f"GROUP {i}:\n"
        report += f"Key: {key}\n"
        for file_info in files:
            report += f"  - {file_info['name']} ({file_info['size']:,} bytes)\n"
        report += "\n"

    return report


def encrypt_files(files, password, method, key_derivation):
    """Encrypt files with specified method"""
    encrypted_files = {}

    for file in files:
        try:
            # Simple encryption simulation (use proper crypto library in production)
            file_data = file.read()

            # Create encryption metadata
            encryption_info = {
                "original_name": file.name,
                "method": method,
                "key_derivation": key_derivation,
                "encrypted_at": datetime.now().isoformat(),
                "encrypted_data": base64.b64encode(file_data).decode('utf-8')  # Simple base64 encoding for demo
            }

            encrypted_content = json.dumps(encryption_info, indent=2).encode('utf-8')
            encrypted_filename = f"{file.name}.encrypted"
            encrypted_files[encrypted_filename] = encrypted_content

        except Exception as e:
            st.error(f"Error encrypting {file.name}: {str(e)}")

    return encrypted_files


def decrypt_files(files, password):
    """Decrypt encrypted files"""
    decrypted_files = {}

    for file in files:
        try:
            content = file.read()
            encryption_info = json.loads(content.decode('utf-8'))

            # Simple decryption (use proper crypto library in production)
            decrypted_data = base64.b64decode(encryption_info['encrypted_data'])

            original_name = encryption_info['original_name']
            decrypted_files[original_name] = decrypted_data

        except Exception as e:
            st.error(f"Error decrypting {file.name}: {str(e)}")

    return decrypted_files


def format_bytes(bytes_value):
    """Format bytes to human readable format"""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if bytes_value < 1024.0:
            return f"{bytes_value:.1f} {unit}"
        bytes_value /= 1024.0
    return f"{bytes_value:.1f} PB"


def generate_size_analysis_report(files, file_types, size_ranges):
    """Generate size analysis report"""
    report = "FILE SIZE ANALYSIS REPORT\n"
    report += "=" * 50 + "\n\n"
    report += f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
    report += f"Total Files Analyzed: {len(files)}\n\n"

    total_size = sum(f.size for f in files)
    report += f"Total Size: {format_bytes(total_size)}\n"
    report += f"Average Size: {format_bytes(total_size / len(files))}\n\n"

    report += "FILE TYPE BREAKDOWN:\n"
    for ext, stats in sorted(file_types.items(), key=lambda x: x[1]['size'], reverse=True):
        report += f"  .{ext}: {stats['count']} files, {format_bytes(stats['size'])}\n"

    report += "\nSIZE DISTRIBUTION:\n"
    for range_name, count in size_ranges.items():
        if count > 0:
            report += f"  {range_name}: {count} files\n"

    return report


# Placeholder functions for remaining tools
def archive_manager():
    """Archive management tool"""
    st.info("Archive Manager - Coming soon!")


def property_editor():
    """File property editor"""
    st.info("Property Editor - Coming soon!")


def file_splitter():
    """File splitting tool"""
    st.info("File Splitter - Coming soon!")


def checksum_generator():
    """Checksum generation tool"""
    st.info("Checksum Generator - Coming soon!")


def directory_sync():
    """Directory synchronization tool"""
    st.info("Directory Sync - Coming soon!")


def content_scanner():
    """File content scanner"""
    st.info("Content Scanner - Coming soon!")


def backup_creator():
    """Backup creation tool"""
    st.info("Backup Creator - Coming soon!")


def file_monitor():
    """File monitoring tool"""
    st.info("File Monitor - Coming soon!")


def smart_organizer():
    """Smart file organizer"""
    st.info("Smart Organizer - Coming soon!")
